{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b3bc22",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19af31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34db64",
   "metadata": {},
   "source": [
    "**Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe82530",
   "metadata": {},
   "outputs": [],
   "source": [
    "depression_corpus = pd.read_csv(\"cleaned_data_lemmatized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3540c2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>depressive</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>totalwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train_subject1095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-04-30 10:52:35</td>\n",
       "      <td>the last line is pretty much the same as the ...</td>\n",
       "      <td>True</td>\n",
       "      <td>line pretty course not read thing realize dupe</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train_subject1095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-04-30 10:25:52</td>\n",
       "      <td>on the flipside generic canned ravioli is jus...</td>\n",
       "      <td>True</td>\n",
       "      <td>flipside generic can ravioli good brand big ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>train_subject1095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-04-30 10:23:26</td>\n",
       "      <td>at least make it illegal to perform on infant...</td>\n",
       "      <td>True</td>\n",
       "      <td>illegal perform infant absolutely matter</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>train_subject1095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-04-30 10:20:06</td>\n",
       "      <td>i feel like i am the only who has never seen ...</td>\n",
       "      <td>True</td>\n",
       "      <td>feel like see sushi gas station</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>train_subject1095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-04-30 10:16:36</td>\n",
       "      <td>if anything it was an act of god for his chut...</td>\n",
       "      <td>True</td>\n",
       "      <td>act god chute open</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295016</th>\n",
       "      <td>295018</td>\n",
       "      <td>train_subject9974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-04-02 16:52:44</td>\n",
       "      <td>yeah i have known too many privates end up wi...</td>\n",
       "      <td>False</td>\n",
       "      <td>yeah know private end stripper hooter girl k...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295017</th>\n",
       "      <td>295019</td>\n",
       "      <td>train_subject9974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-04-02 16:14:56</td>\n",
       "      <td>i am a soldier i am regularly away from home ...</td>\n",
       "      <td>False</td>\n",
       "      <td>soldier regularly away home week month year ...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295018</th>\n",
       "      <td>295020</td>\n",
       "      <td>train_subject9974</td>\n",
       "      <td>ELI5:the button</td>\n",
       "      <td>2015-04-02 04:15:51</td>\n",
       "      <td>please explain the button at rthebutton</td>\n",
       "      <td>False</td>\n",
       "      <td>explain button rthebutton</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295019</th>\n",
       "      <td>295021</td>\n",
       "      <td>train_subject9974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-04-02 02:33:16</td>\n",
       "      <td>stars and stripes is reporting the same thing...</td>\n",
       "      <td>False</td>\n",
       "      <td>star stripe report thing herehttpwwwstripesc...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295020</th>\n",
       "      <td>295022</td>\n",
       "      <td>train_subject9974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-03-31 19:26:05</td>\n",
       "      <td>stranger danger if they give you the gold the...</td>\n",
       "      <td>False</td>\n",
       "      <td>strange danger gold want hole</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295020 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                 id              title                 date  \\\n",
       "0                0  train_subject1095                NaN  2014-04-30 10:52:35   \n",
       "1                1  train_subject1095                NaN  2014-04-30 10:25:52   \n",
       "2                2  train_subject1095                NaN  2014-04-30 10:23:26   \n",
       "3                3  train_subject1095                NaN  2014-04-30 10:20:06   \n",
       "4                4  train_subject1095                NaN  2014-04-30 10:16:36   \n",
       "...            ...                ...                ...                  ...   \n",
       "295016      295018  train_subject9974                NaN  2015-04-02 16:52:44   \n",
       "295017      295019  train_subject9974                NaN  2015-04-02 16:14:56   \n",
       "295018      295020  train_subject9974   ELI5:the button   2015-04-02 04:15:51   \n",
       "295019      295021  train_subject9974                NaN  2015-04-02 02:33:16   \n",
       "295020      295022  train_subject9974                NaN  2015-03-31 19:26:05   \n",
       "\n",
       "                                                     text  depressive  \\\n",
       "0        the last line is pretty much the same as the ...        True   \n",
       "1        on the flipside generic canned ravioli is jus...        True   \n",
       "2        at least make it illegal to perform on infant...        True   \n",
       "3        i feel like i am the only who has never seen ...        True   \n",
       "4        if anything it was an act of god for his chut...        True   \n",
       "...                                                   ...         ...   \n",
       "295016   yeah i have known too many privates end up wi...       False   \n",
       "295017   i am a soldier i am regularly away from home ...       False   \n",
       "295018           please explain the button at rthebutton        False   \n",
       "295019   stars and stripes is reporting the same thing...       False   \n",
       "295020   stranger danger if they give you the gold the...       False   \n",
       "\n",
       "                                               lemmatized  totalwords  \n",
       "0          line pretty course not read thing realize dupe          34  \n",
       "1         flipside generic can ravioli good brand big ...          29  \n",
       "2                illegal perform infant absolutely matter          17  \n",
       "3                         feel like see sushi gas station          16  \n",
       "4                                      act god chute open          14  \n",
       "...                                                   ...         ...  \n",
       "295016    yeah know private end stripper hooter girl k...          28  \n",
       "295017    soldier regularly away home week month year ...          98  \n",
       "295018                          explain button rthebutton           6  \n",
       "295019    star stripe report thing herehttpwwwstripesc...          31  \n",
       "295020                      strange danger gold want hole          14  \n",
       "\n",
       "[295020 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "depression_corpus.drop(\"Unnamed: 0\", axis = 1)\n",
    "depression_corpus.dropna(subset = [\"lemmatized\"], inplace = True)\n",
    "display(depression_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91a07f4",
   "metadata": {},
   "source": [
    "**CBOW**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03eba604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bag_vect = CountVectorizer()\n",
    "bag = bag_vect.fit(depression_corpus[\"lemmatized\"])\n",
    "X_train_bag = bag_vect.transform(X_train)\n",
    "X_test_bag = bag_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4251c",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7991e5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score:  90.02915056606332\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(solver = \"newton-cg\")\n",
    "logReg.fit(X_train_bag, Y_train)\n",
    "logReg_predictions = logReg.predict(X_test_bag)\n",
    "print(\"Logistic Regression Score: \", accuracy_score(logReg_predictions, Y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb14559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     66094\n",
      "           1       0.58      0.15      0.23      7661\n",
      "\n",
      "    accuracy                           0.90     73755\n",
      "   macro avg       0.74      0.57      0.59     73755\n",
      "weighted avg       0.87      0.90      0.87     73755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,logReg_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e5b0c",
   "metadata": {},
   "source": [
    "**SVM**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, naive_bayes, svm\n",
    "SVM = svm.SVC(C=1.0, kernel='rbf',  gamma='auto')\n",
    "SVM.fit(X_train_bag,Y_train)\n",
    "predictions_SVM = SVM.predict(X_test_bag)\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee7ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
